# Sentiment-Analysis-with-BERT-Guided-Project-
Welcome to my first guided project focused on Google's BERT (Bidirectional Encoder-Decoder from Transformers). This project is my initial exploration into transformers! The code for preprocessing and modelling used in this project is primarily taken from a course available on Udemy: [Learn BERT - most powerful NLP algorithm by Google](https://www.udemy.com/course/bert-nlp-algorithm/learn/lecture/29758070?start=1#reviews) by Martin Jocqueviel. The course has been a great resource for my undertanding of how transformers operate in the context of language processing. After this project, my intention is to further work with BERT and learn its aplications in text generation for question answering and text summarization!

This current project is focused on sentiment analysis of Tweets. "Sentiment analysis is the process of analyzing digital text to determine if the emotional tone of the message is positive, negative, or neutral" [Link](https://aws.amazon.com/what-is/sentiment-analysis/). Sentiment analysis has various applications. In commercial sphere for example, the most notable application is using sentiment analysis to undertand customers/users' attitude towards a service or product to improve it [Link](https://aws.amazon.com/what-is/sentiment-analysis/).

The dataset for this project comes from Kaggle, titled [Twitter Sentiment Analysis](https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis). Comprising over 70,000 entries, the dataset contains four distinct sentiment categories: Positive, Negative, Neutral, and Irrelevant. We will go through steps of cleaning as well as preprocessing the dataset for our modelling task. We will build the BERT model from scratch and apply it to Tweets to undertand the underlying sentiment. For more on BERT, check out the course mentined above. 
